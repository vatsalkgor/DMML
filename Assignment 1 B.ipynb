{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the jupyter notebook for DM&ML Assignment 1 Part B"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score,auc,accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  class  b1  b2  b3   b4  b5   b6   b7  b8  b9  ...  pred_minus_obs_H_b9  \\\n",
      "0    d   39  36  57   91  59  101   93  27  60  ...                -2.36   \n",
      "1    h   84  30  57  112  51   98   92  26  62  ...                -2.26   \n",
      "2    s   53  25  49   99  51   93   84  26  58  ...                -1.46   \n",
      "3    s   59  26  49  103  47   92   82  25  56  ...                 2.68   \n",
      "4    d   57  49  66  103  64  106  114  28  59  ...                -2.94   \n",
      "\n",
      "   pred_minus_obs_S_b1  pred_minus_obs_S_b2  pred_minus_obs_S_b3  \\\n",
      "0               -18.41                -1.88                -6.43   \n",
      "1               -16.27                -1.95                -6.25   \n",
      "2               -15.92                -1.79                -4.64   \n",
      "3               -13.77                -2.53                -6.34   \n",
      "4               -21.74                -1.64                -4.62   \n",
      "\n",
      "   pred_minus_obs_S_b4  pred_minus_obs_S_b5  pred_minus_obs_S_b6  \\\n",
      "0               -21.03                -1.60                -6.18   \n",
      "1               -18.79                -1.99                -6.18   \n",
      "2               -17.73                -0.48                -4.69   \n",
      "3               -22.03                -2.34                -6.60   \n",
      "4               -23.74                -0.85                -5.50   \n",
      "\n",
      "   pred_minus_obs_S_b7  pred_minus_obs_S_b8  pred_minus_obs_S_b9  \n",
      "0               -22.50                -5.20                -7.86  \n",
      "1               -23.41                -8.87               -10.83  \n",
      "2               -19.97                -4.10                -7.07  \n",
      "3               -27.10                -7.99               -10.81  \n",
      "4               -22.83                -2.74                -5.84  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_excel('Forest.xlsx')\n",
    "print(raw_data.head())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "random_state randomize the samples. for each random state sampling will be different. but for same random state sampling will remain same for each run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = raw_data.iloc[:,1:].values\n",
    "labels = raw_data.iloc[:,0].values\n",
    "pred_train, pred_test, tar_train, tar_test  = train_test_split(attributes,labels,test_size=0.3,random_state=30,stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_DT = DecisionTreeClassifier(criterion=\"entropy\", random_state=999, max_depth=4)\n",
    "classifier_DT.fit(pred_train,tar_train)\n",
    "predictions_DT = classifier_DT.predict(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8789808917197452\n",
      "0.8789808917197452\n",
      "0.8789808917197452\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(tar_test, predictions_DT))\n",
    "precision = precision_score(y_true=tar_test, y_pred=predictions_DT, average='micro')\n",
    "print(precision)\n",
    "recall = recall_score(y_true=tar_test, y_pred=predictions_DT, average='micro')\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          d        0.85      0.92      0.88        48\n",
      "          h        0.88      0.85      0.86        26\n",
      "          o        1.00      0.72      0.84        25\n",
      "          s        0.87      0.93      0.90        58\n",
      "\n",
      "    accuracy                           0.88       157\n",
      "   macro avg       0.90      0.85      0.87       157\n",
      "weighted avg       0.89      0.88      0.88       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(tar_test,predictions_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44  0  0  4]\n",
      " [ 0 22  0  4]\n",
      " [ 7  0 18  0]\n",
      " [ 1  3  0 54]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(tar_test,predictions_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s ' 's ' 's ' 'd ' 's ' 'd ' 's ' 's ' 's ' 'o ' 'd ' 'o ' 'd ' 's '\n",
      " 's ' 'd ' 'd ' 's ' 'o ' 's ' 's ' 'd ' 'd ' 's ' 'o ' 'd ' 's ' 's '\n",
      " 'h ' 'o ' 'd ' 'd ' 's ' 's ' 'd ' 's ' 'd ' 'd ' 's ' 's ' 's ' 'd '\n",
      " 's ' 'h ' 'o ' 'h ' 'h ' 'h ' 'h ' 's ' 'd ' 'd ' 'o ' 'd ' 'd ' 's '\n",
      " 's ' 's ' 's ' 'o ' 'o ' 'd ' 'h ' 's ' 'd ' 'd ' 'd ' 's ' 'd ' 'd '\n",
      " 'd ' 's ' 'd ' 'd ' 's ' 'd ' 'd ' 'd ' 'h ' 'h ' 's ' 'd ' 's ' 's '\n",
      " 'h ' 's ' 'h ' 's ' 'h ' 'd ' 's ' 's ' 's ' 'd ' 'd ' 'd ' 'd ' 's '\n",
      " 'o ' 'h ' 'd ' 's ' 'd ' 'd ' 'h ' 'd ' 's ' 'o ' 'd ' 'h ' 'd ' 'o '\n",
      " 'h ' 'o ' 's ' 's ' 's ' 'h ' 'd ' 's ' 'd ' 'o ' 's ' 'h ' 'o ' 'd '\n",
      " 's ' 's ' 'o ' 's ' 's ' 's ' 'o ' 's ' 's ' 's ' 'd ' 's ' 's ' 's '\n",
      " 'h ' 's ' 's ' 'd ' 's ' 'o ' 'h ' 'd ' 's ' 'o ' 'o ' 'd ' 's ' 's '\n",
      " 'h ' 'h ' 's ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vatsal/opt/anaconda3/envs/DMML/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "MLP_Classifier = MLPClassifier(max_iter=500)\n",
    "MLP_Classifier.fit(pred_train,np.ravel(tar_train,order='C'))\n",
    "predictions_MLP = MLP_Classifier.predict(pred_test)\n",
    "print(predictions_MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          d        0.90      0.94      0.92        48\n",
      "          h        0.91      0.77      0.83        26\n",
      "          o        1.00      0.80      0.89        25\n",
      "          s        0.85      0.95      0.89        58\n",
      "\n",
      "    accuracy                           0.89       157\n",
      "   macro avg       0.91      0.86      0.88       157\n",
      "weighted avg       0.90      0.89      0.89       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(tar_test,predictions_MLP))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "probDT = classifier_DT.predict_proba(pred_test)\n",
    "probMLP = MLP_Classifier.predict_proba(pred_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Structure for probabilites array\n",
    "[\n",
    "    [\n",
    "        {d: [DT\tMLP]}\n",
    "        {h: [DT\tMLP]}\n",
    "        {o: [DT\tMLP]}\n",
    "        {s: [DT\tMLP]}\n",
    "    ],\n",
    "    ...\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t DecisionTree \t\t MLP\n",
      "d \t [0.04032258064516129, 0.006646672282502062]\n",
      "h \t [0.008064516129032258, 0.004354964147518743]\n",
      "o \t [0.008064516129032258, 0.0003800836479371816]\n",
      "s \t [0.9435483870967742, 0.988618279922042]\n"
     ]
    }
   ],
   "source": [
    "probabilities = []\n",
    "for i in range(len(pred_test)):\n",
    "    probabilities.append({'d':[probDT[i][0],probMLP[i][0]],'h':[probDT[i][1],probMLP[i][1]],'o':[probDT[i][2],probMLP[i][2]],'s':[probDT[i][3],probMLP[i][3]]})\n",
    "firstSampleProbability = probabilities[0]\n",
    "print(\"\\t DecisionTree \\t\\t MLP\")\n",
    "for sampleProbability in probabilities:\n",
    "    for probs in sampleProbability:\n",
    "        print(probs,'\\t',sampleProbability[probs])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q 1.3\n",
    "Pseudo code:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "function averageProbablePrediction (argument 1){\n",
    "       Convert argument 1 to 2d array\n",
    "       Set average probabilites to empty list \n",
    "       Use different trained classifier to predict probabilities of each class\n",
    "       find average matrix \n",
    "       convert matrix to list\n",
    "       FOR each entry in the list\n",
    "           find index with max value in avg list\n",
    "           find class name for that index\n",
    "           append class name to average probabilities\n",
    "       return average probabilities\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s ' 's ' 's ' 'd ']\n",
      "['s ' 's ' 's ' 'd ']\n"
     ]
    }
   ],
   "source": [
    "def averageProbablePrediction(testSet):\n",
    "    global np\n",
    "    testSet = np.atleast_2d(testSet)\n",
    "    averageProbabilities = []\n",
    "    a,b = classifier_DT.predict_proba(testSet),MLP_Classifier.predict_proba(testSet)\n",
    "    averages = (np.add(a,b)/2).tolist()\n",
    "    for avg in averages:\n",
    "        maxValueIndex = avg.index(max(avg))\n",
    "        averageProbabilities.append(classifier_DT.classes_[maxValueIndex])\n",
    "    return np.array(averageProbabilities)\n",
    "print(averageProbablePrediction(pred_test[:4]))\n",
    "print(predictions_MLP[:4])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q 1.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
